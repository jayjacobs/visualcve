---
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
    theme: paper
    code_folding: none
    toc_float:
        collapsed: false
        smooth_scroll: false
---

```{r setup, echo=FALSE}
suppressPackageStartupMessages({
  suppressWarnings({
    library(dplyr)
    library(tibble)
    library(tidyr)
    library(readr)
    library(stringr)
    library(here)
    library(scales)
    library(log4r)
    library(lubridate)
    library(purrr)
    library(arrow)
    library(tidyjson)
    library(ggplot2)
    library(ggrepel)
    library(gt)
  })
})
mainfont <- "Source Sans Pro"
tab <- function (x = c("blue", "orange", "red", "seablue", "green", 
                       "olive", "purple", "pink", "brown", "gray")) {
  tableau <- c(blue = "#4E79A7", orange = "#F28E2B", red = "#E15759", seablue = "#76B7B2", 
               green = "#59A14F", olive = "#EDC948", purple = "#B07AA1", pink = "#FF9DA7", 
               brown = "#9C755F", gray = "#BAB0AC")
  as.vector(tableau[x])
}

theme_set(theme_minimal(base_family=mainfont) +
            theme(panel.grid = element_line(color="gray95"),
                  plot.caption = element_text(size=6, face = "italic", color="gray60"),
                  text = element_text(family=mainfont),
                  legend.title = element_blank(),
                  legend.position="bottom"))
update_geom_defaults('col', list(fill=tab('blue')))
update_geom_defaults('bar', list(fill=tab('blue')))
update_geom_defaults('text', list(family=mainfont, size=8/.pt))
update_geom_defaults('label', list(family=mainfont, size=8/.pt, label.size=NA))
# update_geom_defaults('point', list(shape=21, size=2, fill=tab('blue'), color='white'))
update_geom_defaults('point', list(size=0.5, color=tab('blue')))
update_geom_defaults('line', list(color=tab('blue'), size=0.85))

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  dev = c("png", "cairo_pdf"),
  echo = FALSE,
  fig.retina = 2,
  fig.width = 9,
  fig.height = 3.5
)

```

```{r}
mklab <- function (x, bytes = FALSE) {
    brate <- tibble(cut = c(10^seq(3, 24, 3), Inf), suffix = c("0", 
        "K", "M", "B", "T", "q", "Q", "s", "S"))
    if (bytes) {
        brate <- tibble(cut = c(1024^seq(8), Inf), suffix = c("0", 
            "kB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB"))
    }
    pickup <- tibble(x = x) |> mutate(one = cut(x, breaks = c(-Inf, 
        brate$cut), labels = brate$suffix, right = FALSE)) |> 
        mutate(two = x/sapply(.data$one, function(y) lag(brate$cut)[y])) |> 
        mutate(three = ifelse(.data$two < 10, as.character(round(.data$two, 
            1)), as.character(round(.data$two, 0)))) |> mutate(three = ifelse(is.na(.data$three), 
        as.character(round(.data$x, 0)), paste0(.data$three, 
            .data$one))) |> mutate(four = ifelse(x < 1, x, .data$three))
    pickup$four
}

cves <- read_parquet(here("cache/cveparse/cves.parquet")) |> 
  select(-contains(".x_"))
cvecna <- cves |> 
  select(cve, cna = cveMetadata.assignerShortName) |> 
  drop_na()
totalcve <- cves |> distinct(cve) |> nrow()
totalcna <- cves |> distinct(cveMetadata.assignerShortName) |> nrow()
lastmod <- as.character(as.Date(max(cves$cveMetadata.datePublished, na.rm = TRUE)))

```

# Visual Analysis of the CVE List: `r lastmod`

This exploratory analysis is focused on the data completeness and quality of the primary source for CVE data: https://github.com/CVEProject/cvelistV5. This page is an automated pass through the JSON data.

Last data pull was on `r lastmod` and pulled `r comma(totalcve)` CVEs from `r comma(totalcna)` CNAs.

Each line in the table below represents a unique combinations of field and JSON type. For example, some fields may show up in the JSON as both an array and a string (e.g. `containers.cna.source.defect`) and will therefore show up twice in the listing below. The code will also do it's best to count instances of objects and arrays, but the objects were a lot more difficult, you will notice `NA` in many of the count fields where the JSON type was an object.

Note that the JSON allows for custom fields that start with "x\_", but all of those have been removed since most the 5.0 records contain the full version 4 format of the data in `x_legacyV4Record`. This reduced a lot of the processing required.

```{r cache=FALSE}
#load the varlist generated during collect_json 
varlist <- read_parquet(here("cache", "cveparse", "variables.parquet")) 

if(!file.exists(here("cache", "index_cve_cna_count.parquet")) ||
   file.mtime(here("cache", "index_cve_cna_count.parquet")) < as.Date(lastmod)) {
  # list the files generated by src/collect_json.R
  jsonfile <- tibble(srcfile = list.files(here("cache", "cveparse"), pattern=".parquet$", full.names = TRUE)) |> 
    mutate(src = basename(srcfile)) |> 
    filter(src != "variables.parquet") |>
    mutate(sortfield = gsub(".parquet", "", src)) |> 
    mutate(dots = str_count(sortfield, pattern="\\.")) |> 
    arrange(dots, sortfield)
  
  cve_cna_count <- map_dfr(seq(nrow(jsonfile)), function(i) {
    curfile <- jsonfile$srcfile[i]
    field <- jsonfile$sortfield[i]
    # rename the ID column for this file
    from_name <- paste0(str_split_i(field, pattern="\\.", i=jsonfile$dots[i]+1), "_id")
    names(from_name) <- field
    curdata0 <- read_parquet(curfile) |> 
      mutate(across(where(is.character), function(x) gsub("^n/a$", NA_character_, x)))
    if(length(from_name) & (!field %in% colnames(curdata0))) {
      curdata0 <- curdata0 |> 
        rename(any_of(from_name))
    }
    curdata <- curdata0 |> 
      select(-ends_with("_id")) |> 
      pivot_longer(cols = -cve, names_to = "jsonfield", values_to = "value", 
                   values_drop_na = TRUE, values_transform = as.character) |>
      left_join(cvecna, by="cve") |> 
      summarize(.by=jsonfield, cves = n_distinct(cve), cnas = n_distinct(cna))
    curdata
  })
  write_parquet(cve_cna_count, here("cache", "index_cve_cna_count.parquet"))
} else {
  cve_cna_count <- read_parquet(here("cache", "index_cve_cna_count.parquet"))
}
  
totalcve <- cves |> distinct(cve) |> nrow()
totalcna <- cves |> distinct(cveMetadata.assignerShortName) |> nrow()
```

```{r }
gtable <- varlist |> 
  full_join(cve_cna_count, by=c("name" = "jsonfield")) |>
  mutate(name = str_trunc(name, width=40, side="left")) |> 
  select(`JSON Field` = name, 
         `Observed JSON` = type,
         Instances = n,
         `CVEs` = cves,
         `CNAs` = cnas) 
knitr::kable(gtable, format = "html")
  # gt() |> 
  # tab_header(
  #   title = "Fields Identified in CVEList5",
  #   subtitle = paste(comma(totalcve), 
  #                    "CVEs from", comma(totalcna), "CNAs as of ", 
  #                    as.Date(max(cves$cveMetadata.datePublished, na.rm = TRUE)))) |>
  # fmt_number(columns = c(Instances, CVEs, CNAs), decimals=0, suffixing = FALSE) 

# if (!dir.exists(here("figs", "readme"))) {
#   dir.create(here("figs", "readme"), recursive = TRUE, mode="0755")
# }
# 
# rez <- gtsave(gtable, here::here("figs", "readme", "json_field_counts.png"))
# knitr::include_graphics(rez)

```

```{r eval=FALSE}
cves <- read_parquet(here("cache/cveparse/cves.parquet")) %>% 
  select(-contains(".x_"))
cnapub <- cves %>% 
  mutate(published = as.Date(str_extract(cveMetadata.datePublished, "\\d{4}-\\d{2}-\\d{2}"))) %>% 
  select(cve, cna = cveMetadata.assignerShortName, published) %>% 
  drop_na() %>% 
  mutate(month = floor_date(published, unit="month"))

toplot <- cnapub %>% 
  filter(published >= as.Date("2017-01-01")) %>% 
  count(cna, month) %>% 
  arrange(month, -n) %>% 
  mutate(.by=month, pct = n/sum(n), csum = cumsum(pct), crit = lag(csum) < 0.8) %>% 
  replace_na(list(crit=TRUE)) %>% 
  filter(crit) %>% 
  summarize(.by=month, n=n(), max = max(csum)) %>% 
  arrange(month) %>% 
  mutate(col = as.numeric(month))

colmap <- rainbow(nrow(toplot))
names(colmap) <- toplot$month
gg <- ggplot(toplot, aes(n, max, color=month)) + 
  geom_point() +
  geom_smooth(method="lm") 
  theme(legend.position="none")

# percent of cnas to reach 80% of CVEs
```

## CNAs as proportion of CVEs

```{r}
cves <- read_parquet(here("cache/cveparse/cves.parquet")) %>% 
  select(-contains(".x_"))
cnapub <- cves %>% 
  mutate(published = as.Date(str_extract(cveMetadata.datePublished, "\\d{4}-\\d{2}-\\d{2}"))) %>% 
  select(cve, cna = cveMetadata.assignerShortName, published) %>% 
  drop_na() %>% 
  mutate(month = floor_date(published, unit="month"))

datestep <- seq(max(cnapub$published), as.Date("2017-01-01"), by="-1 week")
toplot <- map_dfr(datestep, function(x) {
  cnapub %>% 
    filter(published <= x,
           published > (x %m-% years(1))) %>%
    count(cna, sort=TRUE) %>% 
    mutate(pct = n/sum(n), 
           csum = cumsum(pct), 
           pct50 = lag(csum) < 0.5,
           pct60 = lag(csum) < 0.6,
           pct70 = lag(csum) < 0.7,
           pct80 = lag(csum) < 0.8,
           pct90 = lag(csum) < 0.9) %>% 
    replace_na(list(pct50=TRUE, pct60=TRUE, pct70=TRUE, pct80=TRUE, pct90=TRUE)) %>% 
    summarize(pct50=sum(pct50), pct60=sum(pct60), pct70=sum(pct70), pct80=sum(pct80), pct90=sum(pct90)) %>% 
    mutate(date = x) 
}) %>% 
  gather(cat, val, -date) %>%
  mutate(txt = paste0(gsub("pct", "", cat), "% of CVEs"))
gg <- ggplot(toplot, aes(date, val, group=txt, color=txt, label=txt)) +
  geomtextpath::geom_textline(text_smoothing=50, size=8/.pt, family=mainfont) +
  # geom_line() +
  scale_y_continuous("Number of CNAs to reach...", limits=c(0,NA),
                     expand=expansion(mult=c(0,0.02)), breaks=seq(0,100,10)) +
  scale_x_date("12-month sliding window from Date") +
  theme(legend.position="none")
gg
```
